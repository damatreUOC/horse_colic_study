---
title: \vspace{8cm}Tipología y ciclo de vida de los datos
subtitle: "Práctica 2: Limpieza y validación de los datos"
author: "Daniel Mato Regueira e Iago Veiras Lens "
date: "Junio de 2019"
header-includes:
  - \usepackage{fancyhdr}
  - \pagestyle{fancy}
  - \usepackage[spanish]{babel}
  - \pagenumbering{gobble}
  - \fancyhead[CO,CE]{}
output:
  pdf_document: 
    number_sections: yes
    toc: no
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Sys.setenv(JAVA_HOME='C:/Program Files/Java/jdk1.8.0_05/')
set.seed(20180509)
```

```{r, include=FALSE}
options(tinytex.verbose = TRUE)
```

\newpage

\pagenumbering{arabic} 
\tableofcontents

\newpage
******

# Detalles de la actividad {-}



\newpage
******

# Descripción del dataset


## Variables del dataset


## Importancia y objetivo del análisis

\newpage
******

# Integración y selección de los datos


Cargamos los dos conjuntos de datos

```{r}
data <- read.csv2(
  file = "https://archive.ics.uci.edu/ml/machine-learning-databases/horse-colic/horse-colic.data",
  header = F, sep = "")
data <- rbind(
  data, 
  read.csv(
    file = "https://archive.ics.uci.edu/ml/machine-learning-databases/horse-colic/horse-colic.test",
    header = F, sep = ""))
```

Damos nombre a las columnas según el repositorio (enlace al documento con la descripción de variables)

```{r}
colnames(data) <- c("surgery", "age", "Hospital_Number", "rectal_temperature", "pulse", 
                    "respiratory_rate", "temperature_of_extremities", "peripheral_pulse", 
                    "mucous_membranes", "capillary_refill_time", "pain", "peristalsis", 
                    "abdominal_distension", "nasogastric_tube", "nasogastric_reflux",
                    "nasogastric_reflux_PH", "rectal_examination", "abdomen", 
                    "packed_cell_volume","total_protein", "abdominocentesis_appearance", 
                    "abdomcentesis_total_protein", "outcome", "surgical_lesion",
                    "type_lesion_1", "type_lesion_2", "type_lesion_3", "cp_data")
```

Convertimos los ? a NaN

```{r}
data[data == '?'] <- NaN
```

Descartamos las variables inútiles

```{r}
data <- data[-c(3, 6, 16, 28)]
```

Refactorizamos las variables categóricas

```{r}
data$surgery <- factor(data$surgery, labels = c("yes", "no"), levels = c(1, 2))
data$age <- factor(data$age, labels = c("adult", "young"), levels = c(1, 9))
data$temperature_of_extremities <- factor(data$temperature_of_extremities, 
                                          labels = c("normal", "warm", "cool", "cold"), 
                                          levels = c(1, 2, 3, 4))
data$peripheral_pulse <- factor(data$peripheral_pulse, 
                                labels = c("normal", "increased", "reduced", "absent"), 
                                levels = c(1, 2, 3, 4))
data$mucous_membranes <- factor(data$mucous_membranes, 
                                labels = c("normal pink", "bright pink", "pale pink", 
                                           "pale cyanotic", "bright red", 
                                           "dark cyanotic"), 
                                levels = c(1, 2, 3, 4, 5, 6))
data$capillary_refill_time <- factor(data$capillary_refill_time, 
                                     labels = c("< 3s", "> 3s"), levels = c(1, 2))
data$pain <- factor(data$pain, 
                    labels = c("alert", "depressed", "intermittent mild pain", 
                               "intermittent severe pain", "continuous severe pain"), 
                    levels = c(1, 2, 3, 4, 5))
data$peristalsis <- factor(data$peristalsis, 
                           labels = c("hypermotile", "normal", "hypomotile", "absent"), 
                           levels = c(1, 2, 3, 4))
data$abdominal_distension <- factor(data$abdominal_distension, 
                                    labels = c("none", "slight", "moderate", "severe"),
                                    levels = c(1, 2, 3, 4))
data$nasogastric_tube <- factor(data$nasogastric_tube, 
                                labels = c("none", "slight", "significant"),
                                levels = c(1, 2, 3))
data$nasogastric_reflux <- factor(data$nasogastric_reflux, 
                                  labels = c("none", "> 1l", "< 1l"),
                                  levels = c(1, 2, 3))
data$rectal_examination <- factor(data$rectal_examination, 
                                  labels = c("normal", "increased", "decreased", 
                                             "absent"),
                                  levels = c(1, 2, 3, 4))
data$abdomen <- factor(data$abdomen, 
                       labels = c("normal", "other", "firm feces li", "distended si", 
                                  "distended li"),
                       levels = c(1, 2, 3, 4, 5))
data$abdominocentesis_appearance <- factor(data$abdominocentesis_appearance, 
                                           labels = c("clear", "cloudy", 
                                                      "serosanguineous"), 
                                           levels = c(1, 2, 3))
data$outcome <- factor(data$outcome, 
                       labels = c("lived", "died", "euthanized"), levels = c(1, 2, 3))
data$surgical_lesion <- factor(data$surgical_lesion, 
                               labels = c("yes", "no"), levels = c(1, 2))
```

Convertimos a continuas las variables numéricas 

```{r message = FALSE, warning = FALSE}
data$rectal_temperature <- as.numeric(levels(data$rectal_temperature))[
  data$rectal_temperature]
data$pulse <- as.numeric(levels(data$pulse))[data$pulse]
data$packed_cell_volume <- as.numeric(levels(data$packed_cell_volume))[
  data$packed_cell_volume]
data$total_protein <- as.numeric(levels(data$total_protein))[data$total_protein]
data$abdomcentesis_total_protein <-
  as.numeric(levels(data$abdomcentesis_total_protein))[data$abdomcentesis_total_protein]
```

Nos interesa el número de lesiones, no el tipo. Convertimos las 3 variables en una única

```{r}
data$type_lesion_1[data$type_lesion_1 > 0] <- 1
data$type_lesion_2[data$type_lesion_2 > 0] <- 1
data$type_lesion_3[data$type_lesion_3 > 0] <- 1
data$num_lesion <- data$type_lesion_1 + data$type_lesion_2 + data$type_lesion_3
data <- data[-c(22, 23, 24)]
```

Resultado de los datos integrados (no limpios)

```{r}
summary(data)
```

\newpage
******

# Limpieza de los datos

En este apartado trataremos con los datos vacíos en el dataset original y realizaremos un análisis de los valores extremos de sus variables continuas.

## Elementos vacíos

En primer lugar, trataremos los registros que tienen pocas variables informadas. Realizamos este paso para evitar generar después registros "casi artificiales", reservándonos la imputación de valores faltantes para aquellos registros que tengan cierto grado de carencia (no superior al 50%). Para ello, eliminaremos las filas del dataset que cumplan dicha condición.

```{r}
filas_nan <- apply(data, 1, function(y) sum(is.na(y))) < dim(data)[2]/2
data <- data[filas_nan,]
```

Para tratar con el resto de valores faltantes, cargaremos en primer lugar la librería "VIM" para estudiar los diferentes patrones de datos faltantes en los registros de nuestro conjunto de datos.

```{r message = FALSE, warning = FALSE}
if (!require("VIM")) install.packages("VIM")
library(VIM)
```

Apoyándonos en la función "aggr", representaremos los patrones de datos faltantes junto con el porcentaje da registros faltantes por variable.

```{r message = FALSE, warning = FALSE}
aggr_plot <- aggr(data, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, 
                  labels=names(data), cex.axis=.7, 
                  gap=3, ylab=c("Histograma de valores faltantes", "Patrón"))
```

Según la tabla anterior, vemos como tanto la variable "abdomcentesis_total_protein" como "abodminocentesis_appearance" tienen, aproximadamente, más de un 50% de registros faltantes, por lo que podemos ignorarla a efectos del estudio que estamos llevando a cabo. Eliminamos de nuestro dataset.

```{r}
data <- data[-c(18, 19)]
```

Para rellenar los datos faltantes, haremos uso de la librería "MICE".

```{r message = FALSE, warning = FALSE}
if (!require("mice")) install.packages("mice")
library(mice)
```

Usando la función de mismo nombre "mice", generaremos cinco capas de imputación y las representaremos para las variables numéricas en un gráfico, de tal manera que podamos comprobar que los patrones de imputación no difieren demasiado respecto de la distribución de datos originales.

```{r}
temp_data <- mice(data, printFlag = F)
stripplot(temp_data, pch=20, cex = 1.2)
```

Veamos ahora qué métodos de imputación está utilizando la función "mice" para las variables de nuestro dataset. Para las variables numéricas se utiliza el método "Predictive mean matching", para las variables categóricas con dos clases se utiliza "Logistic regression" y para variables categóricas con más de dos clases sin orden se utiliza "Polytomous logistic regression".

```{r}
temp_data$method
```

Por último, imputamos los datos faltantes utilizando la función "complete".

```{r}
data <- complete(temp_data)
```

## Valores extremos

En este apartado estudiaremos los valores extremos de todas las variables numéricas. Comenzaremos con "recta_temperature". Tal y como vemos a continuación, todos los valores de temperatura son plausibles, ya que oscilan entre 35.4ºC y 40.8ºC.

```{r}
boxplot.stats(data$rectal_temperature)$out
```

Estudiaremos ahora los outliers de "pulse". En este caso sí que nos encontramos con valores anómalos, ya que pulsos de más de 150 pulsaciones por minuto no son anatómicamente alcanzables por los caballos. Es por esto por lo que eliminaremos los registros que alcanzan dichos valores.

```{r}
boxplot.stats(data$pulse)$out
out_pulse <- boxplot.stats(data$pulse)$out
data <- data[-which(data$pulse %in% out_pulse), ]
```

Veamos ahora el estado de los valores extremos de la variable "packed_cell_volume". En este caso tenemos valores muy elevados y muy pequeños que tampoco son posibles, por lo que al igual que en el caso anterior, eliminamos los regisros pertinentes.

```{r}
boxplot.stats(data$packed_cell_volume)$out
out_cells <- boxplot.stats(data$packed_cell_volume)$out
data <- data[-which(data$packed_cell_volume %in% out_cells), ]
```

En el caso de la variable "total_protein", no encontramos ningún valor extremo, por lo que no tendremos que realizar ninguna correción sobre el conjunto de datos.

```{r}
boxplot.stats(data$total_protein)$out
```

Por último, al tratarse "num_lesion" de una variable calculada en un apartado anterior, no tiene sentido estudiar sus valores extremo, ya que todos ellos son completamente plausibles. Dejamos esta variable intacta.

```{r}
boxplot.stats(data$num_lesion)$out
```

Veamos entonces el tamaño del dataset completamente limpio y listo para ser analizado. Nos quedamos entonces con 328 registros con 20 variables diferentes.

```{r}
dim(data)
```

Para terminar este apartado, generaremos un fichero csv con el conjunto de datos filtrados y tratados.

```{r}
write.csv(data, file = "clean_data_horse_colic.csv", row.names = F)
```

\newpage
******

# Análisis de los datos

En este apartado realizaremos varios análisis sobre el conjunto de datos obtenido en el apartado anterior.

## Selección de grupos a analizar

Uno de los análisis que haremos en este apartado será la comprobación de si los caballos que han sido operados presentan un valor de "total_protein" medio similar a los que no han sido operados. Generaremos estos dos conjuntos de datos y los guardaremos para el estudio posterior.

```{r}
data_oper <- data[data$surgery == "yes", ]$total_protein 
data_noper <- data[data$surgery == "no", ]$total_protein
```

## Comprobación de normalidad y homocedasticidad

Comprobaremos, en primer lugar, la normalidad de las cuatro variables numéricas que podrían presentarla ("rectal_temperature", "pulse", "packed_cell_volume" y "total_protein") mediante el test de normalidad de Shapiro-Wilk. En este caso, ninguna de las cuatro variables presenta una normalidad evidente en su distribución.

```{r}
shapiro.test(data$rectal_temperature)
shapiro.test(data$pulse)
shapiro.test(data$packed_cell_volume)
shapiro.test(data$total_protein)
```

Para realizar la comprobación de la homogeinidad de las varianzas de los dos grupos creados en el apartado anterior, cargaremos la librería "car".

```{r message = FALSE, warning = FALSE}
if (!require("car")) install.packages("car")
library(car)
```

Al realizar el test de Levene sobre la variable "total_protein" según si el caballo ha sido o no operado, comprobamos como no tienen varianza semejantes, ya que se rechaza la hipótesis nula. Si realizamos una gráfica de cajas sobre dichas variables, podemos comprobar fácilmente como se rechaza dicha hipótesis de homocedasticidad.

```{r}
leveneTest(total_protein ~ surgical_lesion, data)
boxplot(data$total_protein, data$surgical_lesion, 
        names = c("surgical_lesion", "no_surgical_lesion"))
```

## Aplicación de pruebas estadísticas

Realizaremos a continuación un estudio de correlación, un contraste de hipótesis y un modelo de regresión logística.

### Estudio de correlación

Para el estudio de correlación, necesitaremos convertir a formato numérico la variable categórica "abdominal_distension". Para ello, es necesario cargar la librería "dummies".

```{r message = FALSE, warning = FALSE}
if (!require("dummies")) install.packages("dummies")
library(dummies)
```

Ayudándonos de dicha librería, extendemos la variable de interés según sus cuatro valores.

```{r}
data <- dummy.data.frame(data, names = "abdominal_distension", 
                         dummy.classes="ALL", sep = "_")
```

Para estudiar la correlación entre las distintas variables numéricas y el "outcome" del caballo, primero deberemos unificar dos de los posibles resultados de dicha variable. Para este estudio, entenderemos que los caballos que han tenido que ser sacrificados ("euthanized") equivalen a los caballos que han muerto ("died"). A continuación, convertiremos la variable categórica en una numérica.

```{r}
levels(data$outcome) <- c(0, 1, 1)
data$outcome <- as.numeric(data$outcome) - 1
```

De entre todos las variable disponibles, seleccionaremos ahora únicamente aquellas que son numéricas.

```{r}
nums <- unlist(lapply(data, is.numeric))
data_nums <- data[ , nums]
```

Para realizar el estudio de correlación de una manera visual y fácil de entender, cargaremos las librerías "corrplot" y "RColorBrewer".

```{r message = FALSE, warning = FALSE}
if (!require("corrplot")) install.packages("corrplot")
library(corrplot)
if (!require("RColorBrewer")) install.packages("RColorBrewer")
library(RColorBrewer)
```

Representamos la correlación entre las diferentes variables continuas, haciendo especial hincapié en los resultados relacionados con la variable "outcome". Podemos ver como las variables con mayor correlación con esta última son "packed_cell_volume", "pulse", "abdominal_distension_moderate" y "num_lesion". Estas variables con mayor correlación serán las que utilizaremos para estimar el modelo de regresión logística del último apartado.

```{r}
corrplot(cor(data_nums), type = "upper", order = "hclust", 
         col = brewer.pal(n = 8, name = "RdYlBu"), diag = F)
```

### Prueba de contraste de hipótesis

Con los dos conjuntos de caballos creados al comienzo de este apartado, realizaremos un contraste de hipótesis sobre las medias de los valores del total de proteínas entre los operados y los no operados. Podemos enunciar el contraste entonces del siguiente modo:

$$H_{0}: \mu_{O} = \mu_{NO}$$
$$H_{1}: \mu_{O} \neq \mu_{NO}$$

Realizaremos entonces un test de Welch sobre las dos muestras para comprobar la hipótesis anterior. En esta caso, dado el p-valor de 0.07, no podemos rechazar la hipótesis nula, por lo que no podemos afirmar que los dos conjuntos tienen una diferencia significativa en sus medias.

```{r}
t.test(data_noper, data_oper)
```

### Modelo de regresión logística

Para estimar el modelo de regresión logística, dividiremos de manera aleatoria el conjunto original en dos muestra, una para el entrenamiento y otra para comprobar la precisión del mismo (80% - 20% respectivamente).

```{r}
train_ind <- sample(seq_len(nrow(data)), size = 0.8*dim(data)[1])
train <- data[train_ind, ]
test <- data[-train_ind, ]
```

Estimamos el modelo de regresión logística mediante el comando "glm" utilizando las variables identificadas como con mayor correlación en el primer análisis realizado sobre el conjunto "train". A continuación, mostraremos por pantalla las características más destacadas del modelo estimado. Podemos ver que todas las variables utilizadas son, hasta cierto punto, significativas.

```{r}
out_model <- glm(outcome ~ pulse + packed_cell_volume + num_lesion + 
                   abdominal_distension_moderate, 
                 data = train, family = "binomial")
summary(out_model)
```

Para poder comprobar la precisión del modelo estimado, tenemos que cargar la librería "caret".

```{r message = FALSE, warning = FALSE}
if (!require("caret")) install.packages("caret")
library(caret)
```

Calcularemos ahora la matriz de confusión sobre los datos de test. Para ello, aplicaremos antes la predicción del modelo estimado sobre el conjunto de datos de test. El resultado arrojado por la matriz es que el modelo tiene más de un 70% de precisión.

```{r}
test_pred <- predict.glm(out_model, test, type="response")
confusionMatrix(factor(round(test_pred)), factor(test$outcome))
```

Cargamos la librería "pROC" para dibujar la curva ROC del modelo estimado.

```{r message = FALSE, warning = FALSE}
if (!require("pROC")) install.packages("pROC")
library(pROC)
```

Por último, representaremos la curva ROC del modelo estimado. Podemos comprobar como la curva resultante nos confirma los buenos resultados obtenidos en la comprobaciones anteriores.

```{r}
curva_roc <- roc(outcome ~ predict.glm(out_model, data, type = "response"), data)
plot(curva_roc)
```

\newpage
******

# Conclusiones


