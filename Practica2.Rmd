---
title: \vspace{8cm}Tipología y ciclo de vida de los datos
subtitle: "Práctica 2: Limpieza y validación de los datos"
author: "Daniel Mato Regueira e Iago Veiras Lens "
date: "Junio de 2019"
header-includes:
  - \usepackage{fancyhdr}
  - \pagestyle{fancy}
  - \usepackage[spanish]{babel}
  - \pagenumbering{gobble}
  - \fancyhead[CO,CE]{}
output:
  pdf_document: 
    number_sections: yes
    toc: no
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Sys.setenv(JAVA_HOME='C:/Program Files/Java/jdk1.8.0_05/')
set.seed(20180509)
```

```{r, include=FALSE}
options(tinytex.verbose = TRUE)
```

\newpage

\pagenumbering{arabic} 
\tableofcontents

\newpage
******


# Detalles de la actividad

## Descripción

En esta práctica se elabora un caso práctico orientado a aprender a identificar los datos relevantes para un proyecto analítico y usar las herramientas de integración, limpieza, validación y análisis de las mismas. Para hacer esta práctica tendréis que trabajar en grupos de 2 personas. Tendréis que entregar un solo archivo con el enlace Github ([https://github.com](https://github.com)) donde se encuentren las soluciones incluyendo los nombres de los componentes del equipo. Podéis utilizar la Wiki de Github para describir vuestro equipo y los diferentes archivos que corresponden a vuestra entrega. Cada miembro del equipo tendrá que contribuir con su usuario Github. 

## Objetivos

Los objetivos concretos de esta práctica son:

* Aprender a aplicar los conocimientos adquiridos y su capacidad de resolución de problemas en entornos nuevos o poco conocidos dentro de contextos más amplios o multidisciplinares.
* Saber identificar los datos relevantes y los tratamientos necesarios (integración, limpieza y validación) para llevar a cabo un proyecto analítico.
* Aprender a analizar los datos adecuadamente para abordar la información contenida en los datos.
* Identificar la mejor representación de los resultados para aportar conclusiones sobre el problema planteado en el proceso analítico.
* Actuar con los principios éticos y legales relacionados con la manipulación de datos en función del ámbito de aplicación.
* Desarrollar las habilidades de aprendizaje que les permitan continuar estudiando de un modo que tendrá que ser en gran medida autodirigido o autónomo.
* Desarrollar la capacidad de búsqueda, gestión y uso de información y recursos en el ámbito de la ciencia de datos

## Competencias

En esta práctica se desarrollan las siguientes competencias del Máster de Data Science:

* Capacidad de analizar un problema en el nivel de abstracción adecuado a cada situación y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.
* Capacidad para aplicar las técnicas específicas de tratamiento de datos (integración, transformación, limpieza y validación) para su posterior análisis.

\newpage
******

# Descripción del dataset
Los datos con los que se trabaja en esta práctica están recogidos en el repositorio de machine learning de la UCI. En concreto, se trata de una colección de 368 casos de cólicos en caballos repartidos en dos ficheros _csv_: *horse-colic.data* y *horse-colic.test*. 

En el dataset se cuenta con, para cada caso, las siguientes variables:

* *surgery*: variable indicadora de procedimiento quirúrgico.
* *age*: edad del caballo (adulto o joven).
* *hospital_number*: número del hospital asignado.
* *rectal_temperature*: temperatura rectal expresada en grados Celsius.
* *pulse*: pulsaciones por minuto.
* *respiratory_rate*: ratio respiratorio del animal.
* *temperature_of_extremities*: temperatura de las extremidades.
* *peripheral_pulse*: pulso periférico del caballo.
* *mucous_membranes*: variable que indica el color de las mucosas.
* *capillary_refill_time*: tiempo de recarga capilar.
* *pain*: nivel de dolor del caballo.
* *peristalsis*: indicador de actividad en la tripa del caballo.
* *abdominal_distension*: distensión abdominal. 
* *nasogastric_tube*: variable que se refiere a la salida de gas del tubo.
* *nasogastric_reflux*: reflujo gástrico.
* *nasogastric_reflux_PH*: ph del reflujo gástrico.
* *rectal_examination*: nivel de heces expulsadas por el animal.
* *abdomen*: calidad del abdomen del caballo.
* *packed_cell_volume*: número de células rojas en sangre.
* *total_protein*: valor total de proteínas en sangre medido en g/dL.
* *abdominocentesis_appearance*: apariencia del abdominocentesis (extraída del fluido de la cavidad abdominal del caballo).
* *abdomcentesis_total_protein*: cantidad total de proteínas en el abdominocenesis.
* *outcome*: variable que indica qué le ha pasado al caballo después del caso (vive, muere o fue sacrificado).
* *surgical_lesion*: indicador si el animal necesitó tratamiento quirúrgico.
* *type_lesion_i*: conjunto de tres variables indicadoras del tipo de lesión del caballo.
* *cp_data*: variable que indica si existen datos de patología para el caso.


Los datasets están localizables en el [repositorio](https://github.com/damatreUOC/horse_colic_study/tree/master/csv) de esta práctica. 


## Importancia y objetivo del análisis

A partir de este conjunto de datos se plantea determinar qué variables tienen más afectación sobre el destino del caballo tras el cólico (*outcome*). Además, utilizaremos técnicas de regresión logística que permitan predecir dicha variable en función de otras características medidas, junto con contrastes de hipótesis que ayuden a identificar propiedades interesantes en la muestra.

Estudios como este tiene una gran importancia en la medicina veterinaria, haciendo que existan datos y conclusiones que los profesionales puedan aprovechar para mejorar sus procedimientos e implementar políticas de cuidado animal adecuadas.

\newpage
******

# Integración y selección de los datos
Comenzaremos la práctica cargando los conjuntos datos del repositorio. Para ello, se utilizará el comando _read.csv2()_ creando así dos dataframes que anexaremos.

```{r}
data <- read.csv2(
  file = "https://archive.ics.uci.edu/ml/machine-learning-databases/horse-colic/horse-colic.data",
  header = F, sep = "")
data <- rbind(
  data, 
  read.csv(
    file = "https://archive.ics.uci.edu/ml/machine-learning-databases/horse-colic/horse-colic.test",
    header = F, sep = ""))
```


Debido a que los dataframes no poseen cabecera, creamos un vector con los nombres de las columnas y se las añadimos al dataset con la función _colnames()_:

```{r}
colnames(data) <- c("surgery", "age", "Hospital_Number", "rectal_temperature", "pulse", 
                    "respiratory_rate", "temperature_of_extremities", "peripheral_pulse", 
                    "mucous_membranes", "capillary_refill_time", "pain", "peristalsis", 
                    "abdominal_distension", "nasogastric_tube", "nasogastric_reflux",
                    "nasogastric_reflux_PH", "rectal_examination", "abdomen", 
                    "packed_cell_volume","total_protein", "abdominocentesis_appearance", 
                    "abdomcentesis_total_protein", "outcome", "surgical_lesion",
                    "type_lesion_1", "type_lesion_2", "type_lesion_3", "cp_data")
```

Realizamos a continuación una inspección breve de las características del dataframe:

```{r}
summary(data)
```


Explorando los datos, podemos ver cómo los valores faltantes están marcados con un '?' en el dataframe. Para simplificar cálculos, convertiremos el caracter '?' por NaN (Not a Number).

```{r}
data[data == '?'] <- NaN
```

Luego, hacemos un estudio de qué variables nos importan para la práctica. Así llegamos a la conclusión de que el número del hospital asignado, el ratio respiratorio, el indicador de si existe patología previa del caballo y el ph del reflujo gástrico no son demasiado relevantes para el estudio; ya sea por no aportar información o por no estar informadas en la mayoría de casos.

```{r}
data <- data[-c(3, 6, 16, 28)]
```

Los datos categóricos están formados por el código, información que no podemos traducir de manera sencilla. Por lo tanto, el siguiente paso que se realiza es la refactorización de las variables categóricas. Este paso hará que sea más sencillo la representación e interpretación de los resultados.

```{r}
data$surgery <- factor(data$surgery, labels = c("yes", "no"), levels = c(1, 2))
data$age <- factor(data$age, labels = c("adult", "young"), levels = c(1, 9))
data$temperature_of_extremities <- factor(data$temperature_of_extremities, 
                                          labels = c("normal", "warm", "cool", "cold"), 
                                          levels = c(1, 2, 3, 4))
data$peripheral_pulse <- factor(data$peripheral_pulse, 
                                labels = c("normal", "increased", "reduced", "absent"), 
                                levels = c(1, 2, 3, 4))
data$mucous_membranes <- factor(data$mucous_membranes, 
                                labels = c("normal pink", "bright pink", "pale pink", 
                                           "pale cyanotic", "bright red", 
                                           "dark cyanotic"), 
                                levels = c(1, 2, 3, 4, 5, 6))
data$capillary_refill_time <- factor(data$capillary_refill_time, 
                                     labels = c("< 3s", "> 3s"), levels = c(1, 2))
data$pain <- factor(data$pain, 
                    labels = c("alert", "depressed", "intermittent mild pain", 
                               "intermittent severe pain", "continuous severe pain"), 
                    levels = c(1, 2, 3, 4, 5))
data$peristalsis <- factor(data$peristalsis, 
                           labels = c("hypermotile", "normal", "hypomotile", "absent"), 
                           levels = c(1, 2, 3, 4))
data$abdominal_distension <- factor(data$abdominal_distension, 
                                    labels = c("none", "slight", "moderate", "severe"),
                                    levels = c(1, 2, 3, 4))
data$nasogastric_tube <- factor(data$nasogastric_tube, 
                                labels = c("none", "slight", "significant"),
                                levels = c(1, 2, 3))
data$nasogastric_reflux <- factor(data$nasogastric_reflux, 
                                  labels = c("none", "> 1l", "< 1l"),
                                  levels = c(1, 2, 3))
data$rectal_examination <- factor(data$rectal_examination, 
                                  labels = c("normal", "increased", "decreased", 
                                             "absent"),
                                  levels = c(1, 2, 3, 4))
data$abdomen <- factor(data$abdomen, 
                       labels = c("normal", "other", "firm feces li", "distended si", 
                                  "distended li"),
                       levels = c(1, 2, 3, 4, 5))
data$abdominocentesis_appearance <- factor(data$abdominocentesis_appearance, 
                                           labels = c("clear", "cloudy", 
                                                      "serosanguineous"), 
                                           levels = c(1, 2, 3))
data$outcome <- factor(data$outcome, 
                       labels = c("lived", "died", "euthanized"), levels = c(1, 2, 3))
data$surgical_lesion <- factor(data$surgical_lesion, 
                               labels = c("yes", "no"), levels = c(1, 2))
```

Además, podemos comprobar que algunas de las variables numéricas no están guardadas así. Añadimos entonces el cambio con las siguientes líneas de comando:

```{r message = FALSE, warning = FALSE}
data$rectal_temperature <- as.numeric(levels(data$rectal_temperature))[
  data$rectal_temperature]
data$pulse <- as.numeric(levels(data$pulse))[data$pulse]
data$packed_cell_volume <- as.numeric(levels(data$packed_cell_volume))[
  data$packed_cell_volume]
data$total_protein <- as.numeric(levels(data$total_protein))[data$total_protein]
data$abdomcentesis_total_protein <-
  as.numeric(levels(data$abdomcentesis_total_protein))[data$abdomcentesis_total_protein]
```

También nos damos cuenta de que hay tres variables que aportan mayor información juntas. Estamos hablando del tipo de lesión. Así, la combinación de estas tres variables nos ayudan a determinar el número de lesiones del caballo.

```{r}
data$type_lesion_1[data$type_lesion_1 > 0] <- 1
data$type_lesion_2[data$type_lesion_2 > 0] <- 1
data$type_lesion_3[data$type_lesion_3 > 0] <- 1
data$num_lesion <- data$type_lesion_1 + data$type_lesion_2 + data$type_lesion_3
data <- data[-c(22, 23, 24)]
```

Finalmente, conseguimos los datos integrados (aunque no limpios).

```{r}
summary(data)
```


\newpage
******

# Limpieza de los datos

En este apartado trataremos con los datos vacíos en el dataset original y realizaremos un análisis de los valores extremos de sus variables continuas.

## Elementos vacíos

En primer lugar, trataremos los registros que tienen pocas variables informadas. Realizamos este paso para evitar generar después registros "casi artificiales", reservándonos la imputación de valores faltantes para aquellos registros que tengan cierto grado de carencia (no superior al 50%). Para ello, eliminaremos las filas del dataset que cumplan dicha condición.

```{r}
filas_nan <- apply(data, 1, function(y) sum(is.na(y))) < dim(data)[2]/2
data <- data[filas_nan,]
```

Para tratar con el resto de valores faltantes, cargaremos en primer lugar la librería "VIM" para estudiar los diferentes patrones de datos faltantes en los registros de nuestro conjunto de datos.

```{r message = FALSE, warning = FALSE}
if (!require("VIM")) install.packages("VIM")
library(VIM)
```

Apoyándonos en la función "aggr", representaremos los patrones de datos faltantes junto con el porcentaje da registros faltantes por variable.

```{r message = FALSE, warning = FALSE}
aggr_plot <- aggr(data, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, 
                  labels=names(data), cex.axis=.7, 
                  gap=3, ylab=c("Histograma de valores faltantes", "Patrón"))
```

Según la tabla anterior, vemos como tanto la variable "abdomcentesis_total_protein" como "abodminocentesis_appearance" tienen, aproximadamente, más de un 50% de registros faltantes, por lo que podemos ignorarlas a efectos del estudio que estamos llevando a cabo.

```{r}
data <- data[-c(18, 19)]
```

Para rellenar los datos faltantes, haremos uso de la librería "MICE".

```{r message = FALSE, warning = FALSE}
if (!require("mice")) install.packages("mice")
library(mice)
```

Usando la función de mismo nombre "mice", generaremos cinco capas de imputación y las representaremos para las variables numéricas en un gráfico, de tal manera que podamos comprobar que los patrones de imputación no difieren demasiado respecto de la distribución de datos originales.

```{r}
temp_data <- mice(data, printFlag = F)
stripplot(temp_data, pch=20, cex = 1.2)
```

Veamos ahora qué métodos de imputación está utilizando la función "mice" para las variables de nuestro dataset. Para las variables numéricas se utiliza el método "Predictive mean matching", para las variables categóricas con dos clases se utiliza "Logistic regression" y para variables categóricas con más de dos clases sin orden se utiliza "Polytomous logistic regression".

```{r}
temp_data$method
```

Por último, imputamos los datos faltantes utilizando la función "complete".

```{r}
data <- complete(temp_data)
```

## Valores extremos

En este apartado estudiaremos los valores extremos de todas las variables numéricas. Comenzaremos con "recta_temperature". Tal y como vemos a continuación, todos los valores de temperatura son plausibles, ya que oscilan entre 35.4ºC y 40.8ºC.

```{r}
boxplot.stats(data$rectal_temperature)$out
```

Estudiaremos ahora los outliers de "pulse". En este caso sí que nos encontramos con valores anómalos, ya que pulsos de más de 150 pulsaciones por minuto no son anatómicamente alcanzables por los caballos. Es por esto por lo que eliminaremos los registros que alcanzan dichos valores.

```{r}
boxplot.stats(data$pulse)$out
out_pulse <- boxplot.stats(data$pulse)$out
data <- data[-which(data$pulse %in% out_pulse), ]
```

Veamos ahora el estado de los valores extremos de la variable "packed_cell_volume". En este caso tenemos valores muy elevados y muy pequeños que tampoco son posibles, por lo que al igual que en el caso anterior, eliminamos los registros pertinentes.

```{r}
boxplot.stats(data$packed_cell_volume)$out
out_cells <- boxplot.stats(data$packed_cell_volume)$out
data <- data[-which(data$packed_cell_volume %in% out_cells), ]
```

En el caso de la variable "total_protein", no encontramos ningún valor extremo, por lo que no tendremos que realizar ninguna corrección sobre el conjunto de datos.

```{r}
boxplot.stats(data$total_protein)$out
```

Por último, al tratarse "num_lesion" de una variable calculada en un apartado anterior, no tiene sentido estudiar sus valores extremo, ya que todos ellos son completamente plausibles. Dejamos esta variable intacta.

```{r}
boxplot.stats(data$num_lesion)$out
```

Veamos entonces el tamaño del dataset completamente limpio y listo para ser analizado. Nos quedamos entonces con 328 registros con 20 variables diferentes.

```{r}
dim(data)
```

Para terminar este apartado, generaremos un fichero csv con el conjunto de datos filtrados y tratados.

```{r}
write.csv(data, file = "clean_data_horse_colic.csv", row.names = F)
```

\newpage
******

# Análisis de los datos

En este apartado realizaremos varios análisis sobre el conjunto de datos obtenido en el apartado anterior.

## Selección de grupos a analizar

Uno de los análisis que haremos en este apartado será la comprobación de si los caballos que han sido operados presentan un valor de "total_protein" medio similar a los que no han sido operados. Generaremos estos dos conjuntos de datos y los guardaremos para el estudio posterior.

```{r}
data_oper <- data[data$surgery == "yes", ]$total_protein 
data_noper <- data[data$surgery == "no", ]$total_protein
```

## Comprobación de normalidad y homocedasticidad

Comprobaremos, en primer lugar, la normalidad de las cuatro variables numéricas que podrían presentarla ("rectal_temperature", "pulse", "packed_cell_volume" y "total_protein") mediante el test de normalidad de Shapiro-Wilk. En este caso, ninguna de las cuatro variables presenta una normalidad evidente en su distribución.

```{r}
shapiro.test(data$rectal_temperature)
shapiro.test(data$pulse)
shapiro.test(data$packed_cell_volume)
shapiro.test(data$total_protein)
```

Para realizar la comprobación de la homogeneidad de las varianzas de los dos grupos creados en el apartado anterior, cargaremos la librería "car".

```{r message = FALSE, warning = FALSE}
if (!require("car")) install.packages("car")
library(car)
```

Al realizar el test de Levene sobre la variable "total_protein" según si el caballo ha sido o no operado, comprobamos como no tienen varianza semejantes, ya que se rechaza la hipótesis nula. Si realizamos una gráfica de cajas sobre dichas variables, podemos comprobar fácilmente como se rechaza dicha hipótesis de homocedasticidad.

```{r}
leveneTest(total_protein ~ surgical_lesion, data)
boxplot(data$total_protein, data$surgical_lesion, 
        names = c("surgical_lesion", "no_surgical_lesion"))
```

## Aplicación de pruebas estadísticas

Realizaremos a continuación un estudio de correlación, un contraste de hipótesis y un modelo de regresión logística.

### Estudio de correlación

Para el estudio de correlación, necesitaremos convertir a formato numérico la variable categórica "abdominal_distension". Para ello, es necesario cargar la librería "dummies".

```{r message = FALSE, warning = FALSE}
if (!require("dummies")) install.packages("dummies")
library(dummies)
```

Ayudándonos de dicha librería, extendemos la variable de interés según sus cuatro valores.

```{r}
data <- dummy.data.frame(data, names = "abdominal_distension", 
                         dummy.classes="ALL", sep = "_")
```

Para estudiar la correlación entre las distintas variables numéricas y el "outcome" del caballo, primero deberemos unificar dos de los posibles resultados de dicha variable. Para este estudio, entenderemos que los caballos que han tenido que ser sacrificados ("euthanized") equivalen a los caballos que han muerto ("died"). A continuación, convertiremos la variable categórica en una numérica.

```{r}
levels(data$outcome) <- c(0, 1, 1)
data$outcome <- as.numeric(data$outcome) - 1
```

De entre todos las variable disponibles, seleccionaremos ahora únicamente aquellas que son numéricas.

```{r}
nums <- unlist(lapply(data, is.numeric))
data_nums <- data[ , nums]
```

Para realizar el estudio de correlación de una manera visual y fácil de entender, cargaremos las librerías "corrplot" y "RColorBrewer".

```{r message = FALSE, warning = FALSE}
if (!require("corrplot")) install.packages("corrplot")
library(corrplot)
if (!require("RColorBrewer")) install.packages("RColorBrewer")
library(RColorBrewer)
```

Representamos la correlación entre las diferentes variables continuas, haciendo especial hincapié en los resultados relacionados con la variable "outcome". Podemos ver como las variables con mayor correlación con esta última son "packed_cell_volume", "pulse", "abdominal_distension_moderate" y "num_lesion". Estas variables con mayor correlación serán las que utilizaremos para estimar el modelo de regresión logística del último apartado.

```{r}
corrplot(cor(data_nums), type = "upper", order = "hclust", 
         col = brewer.pal(n = 8, name = "RdYlBu"), diag = F)
```

### Prueba de contraste de hipótesis

Con los dos conjuntos de caballos creados al comienzo de este apartado, realizaremos un contraste de hipótesis sobre las medias de los valores del total de proteínas entre los operados y los no operados. Podemos enunciar el contraste entonces del siguiente modo:

$$H_{0}: \mu_{O} = \mu_{NO}$$
$$H_{1}: \mu_{O} \neq \mu_{NO}$$

Realizaremos entonces un test de Welch sobre las dos muestras para comprobar la hipótesis anterior. En esta caso, dado el p-valor de 0.07, no podemos rechazar la hipótesis nula, por lo que no podemos afirmar que los dos conjuntos tienen una diferencia significativa en sus medias.

```{r}
t.test(data_noper, data_oper)
```

### Modelo de regresión logística

Para estimar el modelo de regresión logística, dividiremos de manera aleatoria el conjunto original en dos muestra, una para el entrenamiento y otra para comprobar la precisión del mismo (80% - 20% respectivamente).

```{r}
train_ind <- sample(seq_len(nrow(data)), size = 0.8*dim(data)[1])
train <- data[train_ind, ]
test <- data[-train_ind, ]
```

Estimamos el modelo de regresión logística mediante el comando "glm" utilizando las variables identificadas como con mayor correlación en el primer análisis realizado sobre el conjunto "train". A continuación, mostraremos por pantalla las características más destacadas del modelo estimado. Podemos ver que todas las variables utilizadas son, hasta cierto punto, significativas.

```{r}
out_model <- glm(outcome ~ pulse + packed_cell_volume + num_lesion + 
                   abdominal_distension_moderate, 
                 data = train, family = "binomial")
summary(out_model)
```

Para poder comprobar la precisión del modelo estimado, tenemos que cargar la librería "caret".

```{r message = FALSE, warning = FALSE}
if (!require("caret")) install.packages("caret")
library(caret)
```

Calcularemos ahora la matriz de confusión sobre los datos de test. Para ello, aplicaremos antes la predicción del modelo estimado sobre el conjunto de datos de test. El resultado arrojado por la matriz es que el modelo tiene más de un 70% de precisión.

```{r}
test_pred <- predict.glm(out_model, test, type="response")
confusionMatrix(factor(round(test_pred)), factor(test$outcome))
```

Cargamos la librería "pROC" para dibujar la curva ROC del modelo estimado.

```{r message = FALSE, warning = FALSE}
if (!require("pROC")) install.packages("pROC")
library(pROC)
```

Por último, representaremos la curva ROC del modelo estimado. Podemos comprobar como la curva resultante nos confirma los buenos resultados obtenidos en la comprobaciones anteriores.

```{r}
curva_roc <- roc(outcome ~ predict.glm(out_model, data, type = "response"), data)
plot(curva_roc)
```

\newpage
******

# Conclusiones

A lo largo de esta práctica, hemos podido extraer una serie de reflexiones relativas a los casos de cólicos en caballos. En primer lugar, cabe destacar la cantidad de técnicas diferentes que se han tenido que utilizar para poder extraer un dataset valioso para la formación de modelos estadísticos. Esto nos hace pensar que se necesita una mejora en los procedimientos de recogida de datos. Un claro ejemplo es la variable de proteínas totales en abdomcentesis, en donde nos encontramos que faltan más del 60% de los casos. A pesar de esto, después de realizar las correspondientes técnicas de imputación sobre las variables se pudo extraer un conjunto de datos interesante para nuestro estudio. Otra conclusión relativa al pretratamiento de los datos en un proyecto de análisis de datos como este es la cantidad de tiempo y recursos que hay que destinar a preparar un dataset en condiciones para extraer resultados interesantes.

Una vez se han tratado los datos, hemos podido ver que existe una distinta variabilidad del valor total de las proteínas en sangre entre los caballos que han sido sometidos a un procedimiento quirúrgico. Esto puede ser de mucha utilidad para saber cómo tratar al animal después de una operación de este estilo, por ejemplo.

Por último, se ha estudiado la variable outcome (destino final del caballo). Así, con el gráfico de correlación podemos ver de una manera sencilla, qué variables ejercen una mayor influencia sobre el resultado del cólico. Además, se ha creado un modelo de regresión logística con el cual podemos predecir esta variable con una precisión bastante alta utilizando simplemente el pulso, el número de lesiones, la presencia de distensión abdominal moderada y el número de células rojas en sangre (todas estas significativas para el modelo). Este tipo de modelos puede ser de gran utilidad para poder priorizar los tratamientos que se le aplican a los caballos ingresados en función de sus parámetros vitales.
